{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7ac93e-a8e9-4c02-bcaa-9320eb4288db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cersi\\OneDrive\\Documentos\\tfm-stroke\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos: (5110, 12) | X: (5110, 11) | y: (5110,)\n",
      "Numéricas: ['age', 'avg_glucose_level', 'bmi', 'hypertension', 'heart_disease']\n",
      "Categóricas: ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Preprocesador listo (igual al de Notebook 03). SHAP disponible: True\n"
     ]
    }
   ],
   "source": [
    "# Entorno, sin entrenamiento\n",
    "\n",
    "#imports básicos\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "#importar shap e instalar\n",
    "try:\n",
    "    import shap  # noqa\n",
    "except Exception:\n",
    "    !pip -q install shap\n",
    "    import shap  # noqa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#configuración \n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = Path(\"../data/stroke.csv\")\n",
    "OUTPUTS = Path(\"../outputs\")\n",
    "TABLAS = OUTPUTS / \"tablas\"\n",
    "FIGURAS = OUTPUTS / \"figuras\"\n",
    "MODELOS = OUTPUTS / \"modelos\"\n",
    "for p in [TABLAS, FIGURAS, MODELOS]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# cargar datos\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "assert \"stroke\" in df.columns, \"No se encuentra la columna 'stroke' en el CSV.\"\n",
    "assert set(df[\"stroke\"].unique()) <= {0,1}, \"La variable 'stroke' debe ser binaria 0/1.\"\n",
    "\n",
    "y = df[\"stroke\"].astype(int)\n",
    "X = df.drop(columns=[\"stroke\"])\n",
    "\n",
    "# declarar columnas como en Notebook 03\n",
    "num_cols = [\"age\", \"avg_glucose_level\", \"bmi\", \"hypertension\", \"heart_disease\"]\n",
    "cat_cols = [\"gender\", \"ever_married\", \"work_type\", \"Residence_type\", \"smoking_status\"]\n",
    "\n",
    "missing_num = [c for c in num_cols if c not in X.columns]\n",
    "missing_cat = [c for c in cat_cols if c not in X.columns]\n",
    "assert not missing_num and not missing_cat, f\"Faltan columnas -> num:{missing_num} | cat:{missing_cat}\"\n",
    "\n",
    "# preprocesador\n",
    "num_tf = Pipeline(steps=[\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"sc\", StandardScaler())\n",
    "])\n",
    "cat_tf = Pipeline(steps=[\n",
    "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", num_tf, num_cols), (\"cat\", cat_tf, cat_cols)],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "print(\"Datos:\", df.shape, \"| X:\", X.shape, \"| y:\", y.shape)\n",
    "print(\"Numéricas:\", num_cols)\n",
    "print(\"Categóricas:\", cat_cols)\n",
    "print(\"Preprocesador listo (igual al de Notebook 03). SHAP disponible:\", \"shap\" in sys.modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee37567c-f463-4be8-b4c7-efdd8f326449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos guardados:\n",
      "  RL -> ..\\outputs\\modelos\\pipe_RL_classweight.joblib\n",
      "  DT -> ..\\outputs\\modelos\\pipe_DT_classweight.joblib\n",
      "  RF -> ..\\outputs\\modelos\\pipe_RF_classweight.joblib\n",
      "X_prepared shape: (5110, 21)\n",
      "Ejemplo de variables codificadas: ['age' 'avg_glucose_level' 'bmi' 'hypertension' 'heart_disease'\n",
      " 'gender_Female' 'gender_Male' 'gender_Other' 'ever_married_No'\n",
      " 'ever_married_Yes']\n",
      "Archivos guardados para SHAP: ..\\outputs\\modelos\\X_prepared.npy y ..\\outputs\\modelos\\feature_names_after_prepro.csv\n"
     ]
    }
   ],
   "source": [
    "# entrenar y guardar RL, DT y RF (para interpretabilidad)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#  Definir modelos. mismos parámetros del Notebook 03\n",
    "clf_rl = LogisticRegression(\n",
    "    max_iter=5000, class_weight=\"balanced\", solver=\"lbfgs\", random_state=RANDOM_STATE\n",
    ")\n",
    "clf_dt = DecisionTreeClassifier(\n",
    "    criterion=\"gini\", class_weight=\"balanced\", random_state=RANDOM_STATE\n",
    ")\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators=500, class_weight=\"balanced_subsample\",\n",
    "    random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe_rl = Pipeline([(\"prepro\", preprocessor), (\"clf\", clf_rl)])\n",
    "pipe_dt = Pipeline([(\"prepro\", preprocessor), (\"clf\", clf_dt)])\n",
    "pipe_rf = Pipeline([(\"prepro\", preprocessor), (\"clf\", clf_rf)])\n",
    "\n",
    "# Ajustar los tres pipelines\n",
    "pipe_rl.fit(X, y)\n",
    "pipe_dt.fit(X, y)\n",
    "pipe_rf.fit(X, y)\n",
    "\n",
    "# Guardar modelos en outputs/modelos\n",
    "path_rl = MODELOS / \"pipe_RL_classweight.joblib\"\n",
    "path_dt = MODELOS / \"pipe_DT_classweight.joblib\"\n",
    "path_rf = MODELOS / \"pipe_RF_classweight.joblib\"\n",
    "\n",
    "joblib.dump(pipe_rl, path_rl)\n",
    "joblib.dump(pipe_dt, path_dt)\n",
    "joblib.dump(pipe_rf, path_rf)\n",
    "\n",
    "print(\"Modelos guardados:\")\n",
    "print(\"  RL ->\", path_rl)\n",
    "print(\"  DT ->\", path_dt)\n",
    "print(\"  RF ->\", path_rf)\n",
    "\n",
    "#  Obtener X ya transformado y nombres de variables para SHAP\n",
    "\n",
    "prepro_fitted = pipe_rf.named_steps[\"prepro\"]\n",
    "X_prepared = prepro_fitted.transform(X)\n",
    "\n",
    "#columnas después de imputación+OHE+escalado\n",
    "try:\n",
    "    feat_names = prepro_fitted.get_feature_names_out()\n",
    "except AttributeError:\n",
    "    # compatibilidad\n",
    "    feat_names = np.array([f\"f{i}\" for i in range(X_prepared.shape[1])])\n",
    "\n",
    "# Guardar\n",
    "np.save(MODELOS / \"X_prepared.npy\", X_prepared)\n",
    "pd.Series(feat_names).to_csv(MODELOS / \"feature_names_after_prepro.csv\", index=False, header=False)\n",
    "\n",
    "print(\"X_prepared shape:\", X_prepared.shape)\n",
    "print(\"Ejemplo de variables codificadas:\", feat_names[:10])\n",
    "print(\"Archivos guardados para SHAP:\",\n",
    "      MODELOS / \"X_prepared.npy\", \"y\", MODELOS / \"feature_names_after_prepro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b47a5a-1d79-4647-a981-c1fdab2f82d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF cargado. X_prepared: (5110, 21) | n_features: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 10217/10220 [21:55<00:00]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP listo. Matriz: (5110, 21)\n",
      "Figuras guardadas: ..\\outputs\\figuras\\SHAP_summary_beeswarm_RF.png | ..\\outputs\\figuras\\SHAP_importances_bar_RF.png\n",
      "Tabla guardada: ..\\outputs\\tablas\\SHAP_importances_RF.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mean_abs_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.040863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bmi</td>\n",
       "      <td>0.011969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg_glucose_level</td>\n",
       "      <td>0.010972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>0.006428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>smoking_status_never smoked</td>\n",
       "      <td>0.004362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>smoking_status_formerly smoked</td>\n",
       "      <td>0.004067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ever_married_Yes</td>\n",
       "      <td>0.003846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ever_married_No</td>\n",
       "      <td>0.003678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gender_Female</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heart_disease</td>\n",
       "      <td>0.003249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature  mean_abs_shap\n",
       "0                              age       0.040863\n",
       "2                              bmi       0.011969\n",
       "1                avg_glucose_level       0.010972\n",
       "3                     hypertension       0.006428\n",
       "19     smoking_status_never smoked       0.004362\n",
       "18  smoking_status_formerly smoked       0.004067\n",
       "9                 ever_married_Yes       0.003846\n",
       "8                  ever_married_No       0.003678\n",
       "5                    gender_Female       0.003376\n",
       "4                    heart_disease       0.003249"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SHAP para Random Forest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "pipe_rf = joblib.load(MODELOS / \"pipe_RF_classweight.joblib\")\n",
    "rf = pipe_rf.named_steps[\"clf\"]\n",
    "\n",
    "X_prepared = np.load(MODELOS / \"X_prepared.npy\")\n",
    "feat_names = pd.read_csv(MODELOS / \"feature_names_after_prepro.csv\", header=None)[0].values\n",
    "\n",
    "print(\"RF cargado. X_prepared:\", X_prepared.shape, \"| n_features:\", len(feat_names))\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "bg_size = min(1000, X_prepared.shape[0])\n",
    "background = X_prepared[rng.choice(X_prepared.shape[0], size=bg_size, replace=False)]\n",
    "\n",
    "# Dos formas válidas.\n",
    "explainer = shap.Explainer(\n",
    "    rf, \n",
    "    masker=background, \n",
    "    feature_names=feat_names,\n",
    "    algorithm=\"tree\",                  # usa TreeExplainer internamente\n",
    "    model_output=\"probability\"        \n",
    ")\n",
    "\n",
    "#Calcular SHAP \n",
    "shap_exp = explainer(X_prepared, check_additivity=False)\n",
    "\n",
    "# Para binario\n",
    "if shap_exp.values.ndim == 3 and shap_exp.values.shape[2] == 2:\n",
    "    shap_pos = shap_exp.values[:, :, 1]\n",
    "else:\n",
    "    shap_pos = shap_exp.values\n",
    "\n",
    "print(\"SHAP listo. Matriz:\", np.array(shap_pos).shape)\n",
    "\n",
    "#Figuras: summary (beeswarm) y bar\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_pos, X_prepared, feature_names=feat_names, show=False)\n",
    "plt.title(\"SHAP Summary (beeswarm) - Random Forest (probability)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURAS / \"SHAP_summary_beeswarm_RF.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_pos, X_prepared, feature_names=feat_names, plot_type=\"bar\", show=False)\n",
    "plt.title(\"SHAP Importancias (media |SHAP|) - Random Forest (probability)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURAS / \"SHAP_importances_bar_RF.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"Figuras guardadas:\",\n",
    "      FIGURAS / \"SHAP_summary_beeswarm_RF.png\", \"|\",\n",
    "      FIGURAS / \"SHAP_importances_bar_RF.png\")\n",
    "\n",
    "# Tabla de importancias globales\n",
    "mean_abs = np.abs(shap_pos).mean(axis=0)\n",
    "imp_df = pd.DataFrame({\"feature\": feat_names, \"mean_abs_shap\": mean_abs}) \\\n",
    "           .sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "imp_csv = TABLAS / \"SHAP_importances_RF.csv\"\n",
    "imp_df.to_csv(imp_csv, index=False)\n",
    "print(\"Tabla guardada:\", imp_csv)\n",
    "\n",
    "# Mostrar top-10\n",
    "imp_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af8e6a7-b8d7-433b-b5b9-4238c7b417bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices elegidos: [('alto', 50), ('umbral', 88), ('bajo', 249)]  | probs: [np.float64(0.852), np.float64(0.57), np.float64(0.0)]\n",
      "Guardado: ..\\outputs\\figuras\\SHAP_waterfall_RF_alto.png | ..\\outputs\\figuras\\SHAP_decision_RF_alto.png\n",
      "Guardado: ..\\outputs\\figuras\\SHAP_waterfall_RF_umbral.png | ..\\outputs\\figuras\\SHAP_decision_RF_umbral.png\n",
      "Guardado: ..\\outputs\\figuras\\SHAP_waterfall_RF_bajo.png | ..\\outputs\\figuras\\SHAP_decision_RF_bajo.png\n",
      "Listo. Revisa outputs/figuras/ para los PNG locales.\n"
     ]
    }
   ],
   "source": [
    "#Interpretabilidad local con SHAP y 3 ejemplos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap, joblib\n",
    "\n",
    "#Cargar artefactos y probabilidades del RF\n",
    "pipe_rf = joblib.load(MODELOS / \"pipe_RF_classweight.joblib\")\n",
    "rf = pipe_rf.named_steps[\"clf\"]\n",
    "\n",
    "X_prepared = np.load(MODELOS / \"X_prepared.npy\")\n",
    "feat_names = pd.read_csv(MODELOS / \"feature_names_after_prepro.csv\", header=None)[0].values\n",
    "\n",
    "proba = pipe_rf.predict_proba(X)[:, 1]  # probabilidad de clase positiva (stroke)\n",
    "\n",
    "# indices representativos\n",
    "idx_high = int(np.argmax(proba))                               # mayor riesgo\n",
    "idx_mid  = int(np.argmin(np.abs(proba - 0.5)))                 # más cercano al 0.5 (zona de decisión)\n",
    "idx_low  = int(np.argmin(proba))                               # menor riesgo\n",
    "\n",
    "casos = [(\"alto\", idx_high), (\"umbral\", idx_mid), (\"bajo\", idx_low)]\n",
    "print(\"Indices elegidos:\", casos, \" | probs:\", [proba[i] for _, i in casos])\n",
    "\n",
    "#Explainer\n",
    "rng = np.random.default_rng(42)\n",
    "bg_size = min(1000, X_prepared.shape[0])\n",
    "background = X_prepared[rng.choice(X_prepared.shape[0], size=bg_size, replace=False)]\n",
    "\n",
    "explainer = shap.Explainer(\n",
    "    rf,\n",
    "    masker=background,\n",
    "    feature_names=feat_names,\n",
    "    algorithm=\"tree\",\n",
    "    model_output=\"probability\"\n",
    ")\n",
    "\n",
    "def explicar_y_guardar(idx: int, etiqueta: str):\n",
    "    \"\"\"Genera waterfall y decision plot para un índice dado.\"\"\"\n",
    "    \n",
    "    exp = explainer(X_prepared[idx:idx+1], check_additivity=False)\n",
    "    # tomar clase positiva si viene 3D\n",
    "    if exp.values.ndim == 3 and exp.values.shape[2] == 2:\n",
    "        exp1d = shap.Explanation(\n",
    "            values=exp.values[0, :, 1],\n",
    "            base_values=exp.base_values[0, 1],\n",
    "            data=X_prepared[idx],\n",
    "            feature_names=feat_names\n",
    "        )\n",
    "    else:\n",
    "        exp1d = shap.Explanation(\n",
    "            values=exp.values[0],\n",
    "            base_values=np.atleast_1d(exp.base_values)[0],\n",
    "            data=X_prepared[idx],\n",
    "            feature_names=feat_names\n",
    "        )\n",
    "\n",
    "    p = proba[idx]\n",
    "    #Waterfall plo\n",
    "    plt.figure()\n",
    "    shap.plots.waterfall(exp1d, show=False, max_display=15)\n",
    "    plt.title(f\"Waterfall SHAP RF – caso {etiqueta} (idx={idx}, p={p:.3f})\")\n",
    "    plt.tight_layout()\n",
    "    out_wf = FIGURAS / f\"SHAP_waterfall_RF_{etiqueta}.png\"\n",
    "    plt.savefig(out_wf, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    #Decision plot\n",
    "    try:\n",
    "        plt.figure()\n",
    "        shap.decision_plot(exp1d.base_values, exp1d.values, feature_names=feat_names, show=False)\n",
    "        plt.title(f\"Decision plot SHAP – caso {etiqueta} (idx={idx}, p={p:.3f})\")\n",
    "        plt.tight_layout()\n",
    "        out_dec = FIGURAS / f\"SHAP_decision_RF_{etiqueta}.png\"\n",
    "        plt.savefig(out_dec, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"Guardado: {out_wf} | {out_dec}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Guardado: {out_wf} | (decision plot no disponible: {e})\")\n",
    "\n",
    "# Ejecutar para los 3 casos\n",
    "for etq, idx in casos:\n",
    "    explicar_y_guardar(idx, etq)\n",
    "\n",
    "print(\"Listo. Revisa outputs/figuras/ para los PNG locales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c70cc6f-3c28-46d0-ac7c-766e66f46afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv tfm-stroke)",
   "language": "python",
   "name": "tfm-stroke"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
